{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b111f5-b368-445f-b8e7-33541833bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'categories', 'data', 'details', 'feature_names', 'frame', 'target', 'target_names', 'url']\n",
      "Data's shape:  (768, 8)\n",
      "Target's shape:  (768,)\n",
      "Feature names:  ['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age']\n",
      "Target names:  ['class']\n",
      "Textual description: \n",
      "**Author**: [Vincent Sigillito](vgs@aplcen.apl.jhu.edu)  \n",
      "\n",
      "**Source**: [Obtained from UCI](https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes) \n",
      "\n",
      "**Please cite**: [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)  \n",
      "\n",
      "1. Title: Pima Indians Diabetes Database\n",
      " \n",
      " 2. Sources:\n",
      "    (a) Original owners: National Institute of Diabetes and Digestive and\n",
      "                         Kidney Diseases\n",
      "    (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)\n",
      "                           Research Center, RMI Group Leader\n",
      "                           Applied Physics Laboratory\n",
      "                           The Johns Hopkins University\n",
      "                           Johns Hopkins Road\n",
      "                           Laurel, MD 20707\n",
      "                           (301) 953-6231\n",
      "    (c) Date received: 9 May 1990\n",
      " \n",
      " 3. Past Usage:\n",
      "     1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., &\n",
      "        Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast\n",
      "        the onset of diabetes mellitus.  In {it Proceedings of the Symposium\n",
      "        on Computer Applications and Medical Care} (pp. 261--265).  IEEE\n",
      "        Computer Society Press.\n",
      " \n",
      "        The diagnostic, binary-valued variable investigated is whether the\n",
      "        patient shows signs of diabetes according to World Health Organization\n",
      "        criteria (i.e., if the 2 hour post-load plasma glucose was at least \n",
      "        200 mg/dl at any survey  examination or if found during routine medical\n",
      "        care).   The population lives near Phoenix, Arizona, USA.\n",
      " \n",
      "        Results: Their ADAP algorithm makes a real-valued prediction between\n",
      "        0 and 1.  This was transformed into a binary decision using a cutoff of \n",
      "        0.448.  Using 576 training instances, the sensitivity and specificity\n",
      "        of their algorithm was 76% on the remaining 192 instances.\n",
      " \n",
      " 4. Relevant Information:\n",
      "       Several constraints were placed on the selection of these instances from\n",
      "       a larger database.  In particular, all patients here are females at\n",
      "       least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning\n",
      "       routine that generates and executes digital analogs of perceptron-like\n",
      "       devices.  It is a unique algorithm; see the paper for details.\n",
      " \n",
      " 5. Number of Instances: 768\n",
      " \n",
      " 6. Number of Attributes: 8 plus class \n",
      " \n",
      " 7. For Each Attribute: (all numeric-valued)\n",
      "    1. Number of times pregnant\n",
      "    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
      "    3. Diastolic blood pressure (mm Hg)\n",
      "    4. Triceps skin fold thickness (mm)\n",
      "    5. 2-Hour serum insulin (mu U/ml)\n",
      "    6. Body mass index (weight in kg/(height in m)^2)\n",
      "    7. Diabetes pedigree function\n",
      "    8. Age (years)\n",
      "    9. Class variable (0 or 1)\n",
      " \n",
      " 8. Missing Attribute Values: None\n",
      " \n",
      " 9. Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
      "    diabetes\")\n",
      " \n",
      "    Class Value  Number of instances\n",
      "    0            500\n",
      "    1            268\n",
      " \n",
      " 10. Brief statistical analysis:\n",
      " \n",
      "     Attribute number:    Mean:   Standard Deviation:\n",
      "     1.                     3.8     3.4\n",
      "     2.                   120.9    32.0\n",
      "     3.                    69.1    19.4\n",
      "     4.                    20.5    16.0\n",
      "     5.                    79.8   115.2\n",
      "     6.                    32.0     7.9\n",
      "     7.                     0.5     0.3\n",
      "     8.                    33.2    11.8\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Relabeled values in attribute 'class'\n",
      "    From: 0                       To: tested_negative     \n",
      "    From: 1                       To: tested_positive\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "# Question 3a\n",
    "\n",
    "# Load the OpenML diabetes dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "diabetes = fetch_openml(data_id = 37)\n",
    "\n",
    "# Study the attributes in the diabetes dataset\n",
    "print(dir(diabetes))\n",
    "\n",
    "# Feature data's shape and target's shape\n",
    "print(\"Data's shape: \", diabetes.data.shape) \n",
    "print(\"Target's shape: \", diabetes.target.shape)\n",
    "\n",
    "# Feature names and target names\n",
    "print(\"Feature names: \", diabetes.feature_names)\n",
    "print(\"Target names: \", diabetes.target_names)\n",
    "\n",
    "# textual description\n",
    "print(\"Textual description: \", diabetes.DESCR,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c520bbe4-179d-4747-8fc8-6ce40cbdeb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47.0</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23.0</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg   plas  pres  skin   insu  mass   pedi   age            class\n",
       "0     6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0  tested_positive\n",
       "1     1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  tested_negative\n",
       "2     8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  tested_positive\n",
       "3     1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  tested_negative\n",
       "4     0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  tested_positive\n",
       "..    ...    ...   ...   ...    ...   ...    ...   ...              ...\n",
       "763  10.0  101.0  76.0  48.0  180.0  32.9  0.171  63.0  tested_negative\n",
       "764   2.0  122.0  70.0  27.0    0.0  36.8  0.340  27.0  tested_negative\n",
       "765   5.0  121.0  72.0  23.0  112.0  26.2  0.245  30.0  tested_negative\n",
       "766   1.0  126.0  60.0   0.0    0.0  30.1  0.349  47.0  tested_positive\n",
       "767   1.0   93.0  70.0  31.0    0.0  30.4  0.315  23.0  tested_negative\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        skin        insu        mass  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "             pedi         age  \n",
       "count  768.000000  768.000000  \n",
       "mean     0.471876   33.240885  \n",
       "std      0.331329   11.760232  \n",
       "min      0.078000   21.000000  \n",
       "25%      0.243750   24.000000  \n",
       "50%      0.372500   29.000000  \n",
       "75%      0.626250   41.000000  \n",
       "max      2.420000   81.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 3b\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
    "\n",
    "# Get the name of target column stored in list \n",
    "name = diabetes.target_names[0]\n",
    "\n",
    "# Add a new column with the target name (class) and column data in dataframe\n",
    "diabetes_df[name] = diabetes.target\n",
    "                     \n",
    "# Display DataFrame and descriptive statistics\n",
    "display(diabetes_df)\n",
    "display(diabetes_df.describe())\n",
    "\n",
    "# Actually, diabetes.data are stored in DataFrame already in the OpenML dataset.\n",
    "# print(type(diabetes.data))\n",
    "# It is not necessary to create a DataFrame from pandas. but I just follow the question requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2f730-19cd-4375-b5b0-6af3adcda963",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### As many libraries may use repeatly starting from Question 3c, I will consider each question as a separated one from now on and import relevant libraries each time for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81112034-d6de-4a05-a5b4-477355b533ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "# Question 3c\n",
    "from sklearn.datasets import fetch_openml\n",
    "diabetes = fetch_openml(data_id = 37)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size = 0.3)\n",
    "# usually cannot converge with deafult max_iter = 100\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "\n",
    "# the score is more stable when using LogisticRegression(max_iter=200)\n",
    "# clf = make_pipeline(StandardScaler(), SGDClassifier(loss=\"log_loss\"))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ca860ec-1b02-4119-9d00-60d68b0be668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80519481 0.74025974 0.81818182 0.81818182 0.68831169 0.74025974\n",
      " 0.76623377 0.81818182 0.65789474 0.72368421] 0.7576384142173616\n"
     ]
    }
   ],
   "source": [
    "# Question 4d\n",
    "from sklearn.datasets import fetch_openml\n",
    "diabetes = fetch_openml(data_id = 37)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, y = shuffle(diabetes.data, diabetes.target)\n",
    "nb = GaussianNB()\n",
    "scores = cross_val_score(nb, X, y, cv=10)\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b605ddb-f87d-4e67-af9d-dcfebc5c1a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "tested_negative    500\n",
       "tested_positive    268\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3e\n",
    "# Use the aggregate dataset in Question 3b, group by target column and count each category\n",
    "diabetes_df.groupby([name])[name].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ceca40-6ba1-4fb1-98a7-f9515fd1acc2",
   "metadata": {},
   "source": [
    "Question 3e continue\n",
    "\n",
    "There are 268 tested_positive examples and 500 tested_negative examples.\n",
    "\n",
    "The majority class is the tested_negative and the dummy model will always predict tested_negative.\n",
    "\n",
    "Average accuracy = $\\frac{500}{(500 + 268)}$ = 0.6510\n",
    "\n",
    "Both logistic regression model in part c and the naive bayes model in part d give a test score of around 0.75 (on average), which is better than this dummy model with score of 0.6510 by $\\frac{0.75-0.6510}{0.6510} x 100\\% = 15\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "029d5ee5-f34c-4371-b826-e1df39d979ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4a\n",
    "# Load the boston dataset and neglect warnings\n",
    "import warnings\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "077cbc99-bf52-499e-9822-90b016a404cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86897933 0.84157567 0.83844111 0.82438257 0.4536    ] 0.7653957375113629\n"
     ]
    }
   ],
   "source": [
    "# Question 4a (Continue)\n",
    "# Predict numerical label, use Regressor instead of Classifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# As study guide says, train_test_split will shuffle data but cross_val_score will not\n",
    "# shuffle using shuffle() function\n",
    "X, y = shuffle(boston.data, boston.target)\n",
    "boost = AdaBoostRegressor()\n",
    "\n",
    "# Default cv = 5\n",
    "scores = cross_val_score(boost, X, y, n_jobs=-1)\n",
    "# Print the 5 scores and the mean\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "003184b4-e898-407a-a208-7bf5ada67adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59374811 0.48948145 0.46494085 0.61145902 0.62458709] 0.5568433034297416\n"
     ]
    }
   ],
   "source": [
    "# Question 4b\n",
    "# Load the boston dataset and neglect warnings\n",
    "import warnings\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    boston = load_boston()\n",
    "    \n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "    \n",
    "X, y = shuffle(boston.data, boston.target)\n",
    "boost = AdaBoostRegressor(base_estimator=SVR(C=100))\n",
    "\n",
    "scores = cross_val_score(boost, X, y, n_jobs=-1)\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a550d4c1-f5c0-4cca-b78e-9ac5da6cf0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83286318 0.778907   0.87695733 0.84771706 0.89781902] 0.8468527173955602\n"
     ]
    }
   ],
   "source": [
    "# Question 4c\n",
    "import warnings\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    boston = load_boston()\n",
    "    \n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = shuffle(boston.data, boston.target)\n",
    "pipe = make_pipeline(StandardScaler(), SVR(C=100))\n",
    "boost = AdaBoostRegressor(base_estimator=pipe)\n",
    "\n",
    "scores = cross_val_score(boost, X, y, n_jobs=-1)\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31966516-d67e-446a-89ed-1a97ddbd5462",
   "metadata": {},
   "source": [
    "Question 4c (Continue)\n",
    "\n",
    "The mean score of part b is around 0.55 and the mean score of part c is around 0.86. Since part c results in a much better score than that of part b, performance in part b is worse than that of part c.\n",
    "\n",
    "The difference is that part b does not apply standardization using StandardScaler() but part c does.\n",
    "The reason for the difference is that many machine learning algorithms, including SVR are sensitive to the data range. These algorithms can work better (i.e. higher prediction accuracy) when the features are with smaller and similiar data range.\n",
    "\n",
    "Part c will use StandardScaler() to scale the features with smaller and similiar data range before applying SVR, which leads to a better performance of SVR and the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "486ca937-ab87-4fc0-80e5-5db7d9509e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'loss': 'linear',\n",
       " 'n_estimators': 50,\n",
       " 'random_state': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 4d\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "boost = AdaBoostRegressor()\n",
    "display(boost.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e44875b-7d5b-4036-8c6f-641fdec4a448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(base_estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler()),\n",
       "                                                 (&#x27;svr&#x27;, SVR(C=100))]),\n",
       "                  learning_rate=0.4, n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(base_estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler()),\n",
       "                                                 (&#x27;svr&#x27;, SVR(C=100))]),\n",
       "                  learning_rate=0.4, n_estimators=20)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()), (&#x27;svr&#x27;, SVR(C=100))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=100)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor(base_estimator=Pipeline(steps=[('standardscaler',\n",
       "                                                  StandardScaler()),\n",
       "                                                 ('svr', SVR(C=100))]),\n",
       "                  learning_rate=0.4, n_estimators=20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8772066108339814"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 20,\n",
       " 'learning_rate': 0.4,\n",
       " 'base_estimator': Pipeline(steps=[('standardscaler', StandardScaler()), ('svr', SVR(C=100))])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 4e\n",
    "import warnings\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    boston = load_boston()\n",
    "    \n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "import numpy as np\n",
    "\n",
    "X, y = shuffle(boston.data, boston.target)\n",
    "boost = AdaBoostRegressor()\n",
    "\n",
    "# The question did not specific if it is default SVR() or SVR(C=100)\n",
    "# SVR() has a short calculation time, but score is not as good as SVR(C=100)\n",
    "# Also it is not comparable with question 4c\n",
    "# pipe = make_pipeline(StandardScaler(), SVR())\n",
    "pipe = make_pipeline(StandardScaler(), SVR(C=100))\n",
    "\n",
    "param_dist = {\"base_estimator\": (None, pipe),\n",
    "              \"learning_rate\": np.arange(0.1, 2, 0.1), \n",
    "              \"n_estimators\": range(10, 101, 10) \n",
    "             }\n",
    "grid = RandomizedSearchCV(boost, param_dist, n_iter = 30, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "display(grid.best_estimator_, grid.best_score_, grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec3d1c-ce49-4ad0-8616-ec3c4c48b547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
